{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTXhOLj8hfJN"
   },
   "source": [
    "https://github.com/jiechuanjiang/pytorch_DGN/blob/main/Surviving/DGN%2BATOC/config.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(14)\n",
    "import math, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import os,sys\n",
    "from torch.utils import tensorboard as tb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eJJIdzHAhTGs"
   },
   "outputs": [],
   "source": [
    "GRID_DIM = 3 # TODO: Tune this\n",
    "NUM_TASKS = 1 # TODO: Tune this\n",
    "NUM_ATTENTION_HEADS = 1\n",
    "ADJ_THRESHOLD = GRID_DIM / 4 # TODO: Tune this\n",
    "WAIT_TILL_ALL_TASKS_DONE = True\n",
    "USE_OBS_DIST = True\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)\n",
    "\n",
    "def is_legal(x,y):\n",
    "    return (x>=0)&(x<GRID_DIM)&(y>=0)&(y<=GRID_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUxf35c1hpGD"
   },
   "source": [
    "https://github.com/jiechuanjiang/pytorch_DGN/blob/main/Surviving/DGN%2BATOC/buffer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBufferGCare(object):\n",
    "    \"\"\"\n",
    "    Replay buffer for storing the agent's experiences\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size, obs_space, n_action, n_tasks):\n",
    "        \"\"\"\n",
    "        Initialize the replay buffer\n",
    "        \n",
    "        Params:\n",
    "        buffer_size:\n",
    "        obs_space:\n",
    "        n_action:\n",
    "        n_tasks:\n",
    "        \"\"\"\n",
    "        self.buffer_size = buffer_size\n",
    "        self.n_tasks = n_tasks\n",
    "        self.pointer = 0\n",
    "        self.len = 0\n",
    "        self.actions = np.zeros((self.buffer_size,1),dtype = np.int32)\n",
    "        self.rewards = np.zeros((self.buffer_size, 1))\n",
    "        self.dones = np.zeros((self.buffer_size,1))\n",
    "        self.obs = np.zeros((self.buffer_size,n_tasks,obs_space))\n",
    "        self.next_obs = np.zeros((self.buffer_size,n_tasks,obs_space))\n",
    "        self.matrix = np.zeros((self.buffer_size,self.n_tasks,self.n_tasks))\n",
    "        self.next_matrix = np.zeros((self.buffer_size,self.n_tasks,self.n_tasks))\n",
    "\n",
    "    def getBatch(self, batch_size):\n",
    "        \"\"\"\n",
    "        Sample a batch of random entries from the replay buffer\n",
    "        \n",
    "        Params:\n",
    "        batch_size:\n",
    "        \n",
    "        Returns:\n",
    "        obs:\n",
    "        action:\n",
    "        reward\n",
    "        next_obs:\n",
    "        matrix:\n",
    "        next_matrix:\n",
    "        done:\n",
    "        \"\"\"\n",
    "        index = np.random.choice(self.len, batch_size, replace=True)\n",
    "        return self.obs[index], self.actions[index], self.rewards[index], self.next_obs[index], self.matrix[index], self.next_matrix[index], self.dones[index]\n",
    "\n",
    "    def add(self, obs, action, reward, next_obs, matrix, next_matrix, done):\n",
    "        \"\"\"\n",
    "        Add to the replay buffer\n",
    "        \n",
    "        Params:\n",
    "        obs:\n",
    "        action:\n",
    "        reward:\n",
    "        next_obs:\n",
    "        matrix:\n",
    "        next_matrix:\n",
    "        done:\n",
    "        \"\"\"\n",
    "        self.obs[self.pointer] = obs\n",
    "        self.actions[self.pointer] = action\n",
    "        self.rewards[self.pointer] = reward\n",
    "        self.next_obs[self.pointer] = next_obs\n",
    "        self.matrix[self.pointer] = matrix\n",
    "        self.next_matrix[self.pointer] = next_matrix\n",
    "        self.dones[self.pointer] = done\n",
    "        self.pointer = (self.pointer + 1)%self.buffer_size\n",
    "        self.len = min(self.len + 1, self.buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wONM8xyshxjL"
   },
   "source": [
    "https://github.com/jiechuanjiang/pytorch_DGN/blob/main/Surviving/DGN%2BATOC/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTRL_ATT(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, din):\n",
    "        super(MTRL_ATT, self).__init__()\n",
    "        self.fc1 = nn.Linear(din, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.fc1(x))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = F.sigmoid(self.fc3(y))\n",
    "        return y\n",
    "\n",
    "class MTRL_Encoder(nn.Module): # TODO: Need to make it a CNN for higher dim obs space like MetaWorld\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, din=32, hidden_dim=128):\n",
    "        super(MTRL_Encoder, self).__init__()\n",
    "        self.fc = nn.Linear(din, hidden_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = F.tanh(self.fc(x))\n",
    "        return embedding\n",
    "\n",
    "class MTRL_AttModel(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, n_node, din, hidden_dim, dout):\n",
    "        super(MTRL_AttModel, self).__init__()\n",
    "        self.fcv = nn.Linear(din, hidden_dim)\n",
    "        self.fck = nn.Linear(din, hidden_dim)\n",
    "        self.fcq = nn.Linear(din, hidden_dim)\n",
    "        self.fcout = nn.Linear(hidden_dim, dout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        v = F.tanh(self.fcv(x))\n",
    "        q = F.tanh(self.fcq(x))\n",
    "        k = F.tanh(self.fck(x)).permute(0,2,1)\n",
    "        att = F.softmax(torch.mul(torch.bmm(q,k), mask) - 9e15*(1 - mask),dim=2)\n",
    "        # Note: Order of applying adj matrix is different than that in paper. Don't get confused!\n",
    "        out = torch.bmm(att,v)\n",
    "        return out\n",
    "\n",
    "class MTRL_Q_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, dout):\n",
    "        super(MTRL_Q_Net, self).__init__()\n",
    "        # NOTE: This is now modified to have both h vectors from both of the attention layers\n",
    "        # concatenated - originally it was only getting the h vector of the last layer\n",
    "        # so the input dim of the linear layer was hidden_dim\n",
    "        self.fc = nn.Linear(hidden_dim*(NUM_ATTENTION_HEADS + 1), dout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = F.relu(self.fc(x))\n",
    "        return q\n",
    "\n",
    "    \n",
    "class MTRL_DGN(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,n_tasks,num_inputs,hidden_dim,num_actions):\n",
    "        super(MTRL_DGN, self).__init__()\n",
    "\n",
    "        self.encoder = MTRL_Encoder(num_inputs,hidden_dim)\n",
    "        self.attention_heads = [MTRL_AttModel(n_tasks,hidden_dim,hidden_dim,hidden_dim).cuda() for _ in range(NUM_ATTENTION_HEADS)]\n",
    "        self.q_net = MTRL_Q_Net(hidden_dim,num_actions)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        mask = mask.cuda()\n",
    "        h = self.encoder(x)\n",
    "        attention_heads = [h]\n",
    "        for i in range(NUM_ATTENTION_HEADS):\n",
    "            h = h.cuda()\n",
    "            h = self.attention_heads[i](h, mask)\n",
    "            attention_heads.append(h)\n",
    "#         h2 = self.att_1(h1, mask)\n",
    "#         h3 = self.att_2(h2, mask) \n",
    "        \n",
    "        # TODO: try concatentation for MTRL\n",
    "        \n",
    "        h = torch.cat(attention_heads, dim=-1)\n",
    "#         h4 = torch.cat((h1,h2,h3),dim=-1)\n",
    "        q = self.q_net(h)\n",
    "        # Note: No concatenation done. Output of last attention head used directly\n",
    "        # Note: 2 attention heads used\n",
    "        return q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxG8-x_piggE"
   },
   "source": [
    "https://github.com/jiechuanjiang/pytorch_DGN/blob/main/Surviving/DGN%2BATOC/surviving.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldWithCare(object):\n",
    "    \n",
    "    def __init__(self, n_tasks):\n",
    "        \"\"\"\n",
    "        Initialize the gridworld\n",
    "        \n",
    "        Params:\n",
    "        n_tasks:\n",
    "        \"\"\"\n",
    "        super(GridWorldWithCare, self).__init__()\n",
    "        self.n_action = 4\n",
    "        self.n_tasks = n_tasks\n",
    "        # TODO: maybe include food as part of task, reach dest with > 0 food or something\n",
    "        self.tasks = [0]*self.n_tasks\n",
    "        self.agent = [-1, -1]\n",
    "        self.build_env()\n",
    "\n",
    "        self.dones = np.zeros(self.n_tasks) # Array to indicate whether each task is done or not -- used to calculate rewards\n",
    "        self.steps = 0\n",
    "        if USE_OBS_DIST:\n",
    "            self.len_obs = self.n_tasks + 2\n",
    "        else:\n",
    "            self.len_obs = (self.n_tasks+1)*2\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the gridworld\n",
    "        \n",
    "        Returns:\n",
    "        obs:\n",
    "        adj:\n",
    "        \"\"\"\n",
    "\n",
    "        self.build_env()\n",
    "        self.dones = np.zeros(self.n_tasks)\n",
    "        self.steps = 0\n",
    "        return self.get_obs(), self.get_adj()\n",
    "\n",
    "    def build_env(self):\n",
    "        \"\"\"\n",
    "        Build the gridworld\n",
    "        \"\"\"\n",
    "        for i in range(self.n_tasks):\n",
    "            x = np.random.randint(0, GRID_DIM)\n",
    "            y = np.random.randint(0, GRID_DIM)\n",
    "            self.tasks[i] = [x, y]\n",
    "            print(\"TASK NUMBER \", i, \" DEST: \", x, y)\n",
    "        self.agent[0] = np.random.randint(0, GRID_DIM)\n",
    "        self.agent[1] = np.random.randint(0, GRID_DIM)\n",
    "\n",
    "    def get_obs(self):\n",
    "        \"\"\"\n",
    "        Get observations\n",
    "        \n",
    "        Returns:\n",
    "        obs:\n",
    "        \"\"\"\n",
    "        # TODO: change this for MTRL \n",
    "        obs = []\n",
    "        \n",
    "        x_agent = self.agent[0]\n",
    "        y_agent = self.agent[1]\n",
    "\n",
    "        obs.append(x_agent/GRID_DIM)\n",
    "        obs.append(y_agent/GRID_DIM)\n",
    "\n",
    "        # \t\tfor i in range(-1,2):\n",
    "        # \t\t\tfor j in range(-1,2):\n",
    "        # \t\t\t\tobs.append(self.maze[x_agent+i][y_agent+j])\n",
    "\n",
    "        if USE_OBS_DIST:\n",
    "            for i in range(self.n_tasks):\n",
    "                obs.append(math.sqrt((self.tasks[i][0]-x_agent)**2 + (self.tasks[i][1]-y_agent)**2)/GRID_DIM)\n",
    "        else:\n",
    "            for i in range(self.n_tasks):\n",
    "                obs.append((self.tasks[i][0]-x_agent)/GRID_DIM)\n",
    "                obs.append((self.tasks[i][1]-y_agent)/GRID_DIM)\n",
    "\n",
    "        # TODO: 1. if we include maze state or not, and if we do, we would need to figure out\n",
    "        # how to effectively send that along with task destinations\n",
    "        \n",
    "        #Idea: use distance between agent and task as obs\n",
    "        \n",
    "        return obs\n",
    "\n",
    "    def get_adj(self): # TODO: Change this to use task description encoding. \n",
    "        # In this case task description is the location of the destination.\n",
    "        \"\"\"\n",
    "        Get adjacency matrix\n",
    "        \n",
    "        Returns:\n",
    "        adj:\n",
    "        \"\"\"\n",
    "        adj = np.zeros((self.n_tasks, self.n_tasks))\n",
    "\n",
    "        # Calculate adjacency regarding to the distances of the tasks respect to the agent\n",
    "        x_agent, y_agent = self.agent[0], self.agent[1]\n",
    "\n",
    "        # HARD ATTENTION\n",
    "        # Traverse through the tasks and calculate the Euclidean distance between them and the agent\n",
    "#         for i in range(self.n_tasks):\n",
    "#             x_task_i, y_task_i = self.tasks[i][0] - x_agent, self.tasks[i][1] - y_agent\n",
    "#             for j in range(self.n_tasks):\n",
    "#                 x_task_j, y_task_j = self.tasks[j][0] - x_agent, self.tasks[j][1] - y_agent\n",
    "#                 task_dist = math.sqrt((x_task_j - x_task_i)**2 + (y_task_i - y_task_j)**2)\n",
    "#                 if task_dist <= ADJ_THRESHOLD:\n",
    "#                     adj[i,j] = 1\n",
    "#                     adj[j,i] = 1\n",
    "                    \n",
    "        # SOFT ATTENTION\n",
    "#         adj = np.ones((self.n_tasks, self.n_tasks)) # NOTE: \n",
    "        for i in range(self.n_tasks):\n",
    "            x_task_i, y_task_i = self.tasks[i][0]-x_agent, self.tasks[i][1]-y_agent\n",
    "            for j in range(self.n_tasks):\n",
    "                x_task_j, y_task_j = self.tasks[j][0]-x_agent, self.tasks[j][1]-y_agent\n",
    "                # Instead of having 1 or 0s, have their vectoral positions according to each other\n",
    "                task_dist = math.sqrt((x_task_j - x_task_i)**2 + (y_task_j - y_task_i)**2)\n",
    "                \n",
    "                # Set this distance / GRID_DIM\n",
    "                adj[i,j] = 1 - float(task_dist)/GRID_DIM # Extract from 1 bc the closer the better\n",
    "                adj[j,i] = 1 - float(task_dist)/GRID_DIM\n",
    "\n",
    "        return adj\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Take one step in the gridworld according to the given actions\n",
    "        \n",
    "        Params:\n",
    "        action:\n",
    "        \n",
    "        Returns:\n",
    "        obs:\n",
    "        adj:\n",
    "        reward:\n",
    "        all_tasks_done:\n",
    "        \"\"\"\n",
    "\n",
    "        # There are 4 different actions for the agent\n",
    "        # If there is any place to go in the maze then the agent will go \n",
    "        # 0: Move up, 1: Move down, 2: Move left, 3: Move right\n",
    "\n",
    "        self.steps += 1\n",
    "        x_agent, y_agent = self.agent[0], self.agent[1]\n",
    "        if action == 0: # Move up (decrease x by one)\n",
    "            if is_legal(x_agent-1, y_agent):\n",
    "                # Change the agent and the maze\n",
    "                self.agent[0] -= 1\n",
    "\n",
    "        elif action == 1: # Move down (increase x by one)\n",
    "            if is_legal(x_agent+1, y_agent):\n",
    "                # Change the agent and the maze\n",
    "                self.agent[0] += 1\n",
    "\n",
    "        elif action == 2: # Move left (decrease y by one)\n",
    "            if is_legal(x_agent, y_agent-1):\n",
    "                # Change the agent and the maze\n",
    "                self.agent[1] -= 1\n",
    "\n",
    "        elif action == 3: # Move right (increase y by one)\n",
    "            if is_legal(x_agent, y_agent+1):\n",
    "                # Change the agent and the maze\n",
    "                self.agent[1] += 1\n",
    "                \n",
    "        # Calculate the rewards for each task\n",
    "        rewards = [0] * self.n_tasks\n",
    "        total_reward = 0\n",
    "\n",
    "        # Check if you reached to any destinations here\n",
    "        new_agent_x, new_agent_y = self.agent[0], self.agent[1]\n",
    "        for i in range(self.n_tasks):\n",
    "            if self.tasks[i][0] == new_agent_x and self.tasks[i][1] == new_agent_y:\n",
    "                if self.dones[i] == 0:\n",
    "                    self.dones[i] = 1\n",
    "                    rewards[i] = 10\n",
    "                    total_reward += 10\n",
    "                    print(\"Task \", i, \" completed at step \", self.steps)\n",
    "                    \n",
    "#         TODO: Uncomment these lines for soft reward\n",
    "            else:\n",
    "                total_reward += 1.0/float((math.sqrt((self.tasks[i][0]-new_agent_x)**2 + (self.tasks[i][1]-new_agent_y)**2)))\n",
    "                \n",
    "\n",
    "        # Only if all the tasks are done, then the episode is done\n",
    "        all_tasks_done = not (0 in self.dones)\n",
    "        score = sum(self.dones) / len(self.dones)\n",
    "        \n",
    "\n",
    "\n",
    "        return self.get_obs(), self.get_adj(), total_reward, all_tasks_done, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for making the training with different set of hyper parameters\n",
    "class Training:\n",
    "    \"\"\"\n",
    "    This class trains the model and holds the highest scores and the hyper parameter combination that gave us that\n",
    "    highest score. \n",
    "    Prints tryout_index -> highest_score_in_that_tryout for each tryout to the file\n",
    "    \n",
    "    params:\n",
    "    test_results_file: name of the file to hold the results\n",
    "    vizier: boolean to indicate whether to do hyper parameter search\n",
    "    \"\"\"\n",
    "    def __init__(self, file_name, vizier=False): # vizier indicates whether to do hyper param research\n",
    "        self.file_name = file_name\n",
    "        self.file = open(file_name, \"w+\")\n",
    "        self.vizier = vizier # if vizier is true then the class makes \n",
    "\n",
    "        if self.vizier:\n",
    "\n",
    "            # Dictionary to give us all options for hyper parameters\n",
    "            self.hyper_params = {\n",
    "                'hidden_dim': [64], # 2\n",
    "                'max_step': [5000], # 1\n",
    "                'gamma': [0.99], # 1\n",
    "                'n_episode': [800], # 1\n",
    "                'buffer_size': [100000, 10000000], # 3\n",
    "                'batch_size': [128], # 1\n",
    "                'n_epoch': [100], # 2\n",
    "                'epsilon': [0.5, 0.7, 0.9], # 3\n",
    "                'tau': [0.95], # 2\n",
    "                'learning_rate': [0.0005, 0.001, 0.005] # 3\n",
    "            }\n",
    "\n",
    "            self.tryouts = []\n",
    "            for key, value in self.hyper_params.items():\n",
    "                tryouts_len = len(self.tryouts)\n",
    "                if tryouts_len == 0:\n",
    "                    for param in value:\n",
    "                        self.tryouts.append({key : param})\n",
    "\n",
    "                else:\n",
    "                    params_len = len(value)\n",
    "                    for i in range(params_len-1):\n",
    "                        for j in range(tryouts_len):\n",
    "                            self.tryouts.append(copy.deepcopy(self.tryouts[j]))\n",
    "\n",
    "                    for j in range(params_len):\n",
    "                        for i in range(tryouts_len):\n",
    "                            self.tryouts[j*tryouts_len+i][key] = value[j]\n",
    "\n",
    "            print('len(tryouts): {}'.format(len(self.tryouts)))\n",
    "            print('tryouts: {}'.format(tryouts))\n",
    "            self.num_tryout = len(self.tryouts)\n",
    "            self.highest_scores = [0] * self.num_tryout # This will hold the highest score in each try out\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            self.hidden_dim = 64\n",
    "            self.max_step = 5000 #originally 500\n",
    "            self.gamma = 0.99\n",
    "            self.n_episode = 800 #originally 800\n",
    "            self.buffer_size = 1000000 #change back to 65000\n",
    "            self.batch_size = 64 #change back to 64\n",
    "            self.n_epoch = 100 #orginally 25\n",
    "            self.epsilon = 0.7 #originally 0.9\n",
    "            self.tau = 0.95\n",
    "            self.learning_rate = 0.00005\n",
    "            \n",
    "            self.num_tryout = 1\n",
    "            self.highest_scores = [0] * self.num_tryout # This will hold the highest score in each try out\n",
    "        \n",
    "            \n",
    "    def train(self):\n",
    "        env = GridWorldWithCare(NUM_TASKS)\n",
    "        observation_space = env.len_obs\n",
    "        n_actions = env.n_action\n",
    "        n_tasks = env.n_tasks\n",
    "        \n",
    "        # Set the hyper parameters \n",
    "        for tryout_index in range(self.num_tryout):\n",
    "            if self.vizier:\n",
    "                self.hidden_dim = self.tryouts[tryout_index]['hidden_dim']\n",
    "                self.max_step = self.tryouts[tryout_index]['max_step']\n",
    "                self.gamma = self.tryouts[tryout_index]['gamma']\n",
    "                self.n_episode = self.tryouts[tryout_index]['n_episode']\n",
    "                self.buffer_size = self.tryouts[tryout_index]['buffer_size']\n",
    "                self.batch_size = self.tryouts[tryout_index]['batch_size']\n",
    "                self.n_epoch = self.tryouts[tryout_index]['n_epoch']\n",
    "                self.epsilon = self.tryouts[tryout_index]['epsilon']\n",
    "                self.tau = self.tryouts[tryout_index]['tau']\n",
    "                self.learning_rate = self.tryouts[tryout_index]['learning_rate']\n",
    "                \n",
    "            print('-------\\nTRYOUT[{}]: (hidden_dim={}, max_step={}, gamma={}, n_episode={}, buffer_size={}, batch_size={}, n_epoch={}, epsilon={}, tau={}, learning_rate={})'.format(\n",
    "                tryout_index, self.hidden_dim, self.max_step, self.gamma, self.n_episode, self.buffer_size, self.batch_size, self.n_epoch, self.epsilon, self.tau, self.learning_rate\n",
    "            ))\n",
    "                \n",
    "                \n",
    "            buff = ReplayBufferGCare(self.buffer_size, observation_space, n_actions, n_tasks)\n",
    "            model = MTRL_DGN(n_tasks, observation_space, self.hidden_dim, n_actions).cuda()\n",
    "            model_tar = MTRL_DGN(n_tasks, observation_space, self.hidden_dim, n_actions).cuda()\n",
    "            optimizer = optim.Adam(model.parameters(), lr = self.learning_rate)\n",
    "            criterion = nn.BCELoss()\n",
    "            \n",
    "            M_Null = torch.Tensor(np.array([np.eye(n_tasks)] * self.batch_size)).cuda()\n",
    "            M_ZERO = torch.Tensor(np.zeros((self.batch_size, n_tasks, n_tasks))).cuda()\n",
    "        \n",
    "            i_episode = 0\n",
    "            score = 0\n",
    "            \n",
    "            if not self.vizier:\n",
    "                tb_summary_writer = tb.SummaryWriter(log_dir = \"./TB-Logs/\"+self.file_name.split(\".txt\")[0])\n",
    "                global_step_count = 0\n",
    "            \n",
    "            while i_episode < self.n_episode:\n",
    "                if i_episode > 40:\n",
    "                    self.epsilon -= 0.001\n",
    "                    if self.epsilon < 0.01:\n",
    "                        self.epsilon = 0.01\n",
    "                        \n",
    "                i_episode+=1\n",
    "                steps = 0\n",
    "                obs, adj = env.reset()\n",
    "                terminated = False\n",
    "                obs = np.resize(obs, (n_tasks, observation_space))\n",
    "                \n",
    "                start_step = global_step_count\n",
    "\n",
    "                if WAIT_TILL_ALL_TASKS_DONE:\n",
    "                    while not terminated:\n",
    "                        steps+=1 \n",
    "                        global_step_count += 1\n",
    "                        # Get the action with forward prop and add the obs, adjs to replay buffer\n",
    "                        q = model(torch.Tensor(np.array([obs])).cuda(), torch.Tensor(np.array([adj])).cuda())[0,0,:]\n",
    "                        if np.random.rand() < self.epsilon:\n",
    "                            action = np.random.randint(n_actions)\n",
    "                        else:\n",
    "                            action = q.argmax().item()\n",
    "                        next_obs, next_adj, reward, terminated, step_score = env.step(action)\n",
    "                        if not self.vizier:\n",
    "                            tb_summary_writer.add_scalar(\"Reward on one step\", reward, global_step_count)\n",
    "                        next_obs = np.resize(next_obs, (n_tasks, observation_space))\n",
    "                        buff.add(np.array(obs),action,reward,np.array(next_obs),adj,next_adj,terminated)\n",
    "\n",
    "                        obs = next_obs\n",
    "                        adj = next_adj\n",
    "                        score += step_score\n",
    "                        \n",
    "                else:\n",
    "                    while steps < self.max_step:\n",
    "                        steps+=1 \n",
    "                        global_step_count += 1\n",
    "                        # Get the action with forward prop and add the obs, adjs to replay buffer\n",
    "                        q = model(torch.Tensor(np.array([obs])).cuda(), torch.Tensor(np.array([adj])).cuda())[0,0,:]\n",
    "                        if np.random.rand() < self.epsilon:\n",
    "                            action = np.random.randint(n_actions)\n",
    "                        else:\n",
    "                            action = q.argmax().item()\n",
    "                        next_obs, next_adj, reward, terminated, step_score = env.step(action)\n",
    "                        if not self.vizier:\n",
    "                            tb_summary_writer.add_scalar(\"Reward on one step\", reward, global_step_count)\n",
    "                        next_obs = np.resize(next_obs, (n_tasks, observation_space))\n",
    "                        buff.add(np.array(obs),action,reward,np.array(next_obs),adj,next_adj,terminated)\n",
    "\n",
    "                        obs = next_obs\n",
    "                        adj = next_adj\n",
    "                        score += step_score\n",
    "\n",
    "                if i_episode%20==0:\n",
    "                    print(score/20)\n",
    "                    if not self.vizier:\n",
    "                        tb_summary_writer.add_scalar(\"Score\", score/20, global_step_count)\n",
    "                    else:\n",
    "                        if score/20 > self.highest_scores[tryout_index]:\n",
    "                            self.highest_scores[tryout_index] = score/20\n",
    "                    score = 0\n",
    "                \n",
    "                \n",
    "                episode_loss = 0\n",
    "                \n",
    "                # Train the model\n",
    "                for e in range(self.n_epoch):\n",
    "                    O,A,R,Next_O,Matrix,Next_Matrix,D = buff.getBatch(self.batch_size)\n",
    "                    O = torch.Tensor(O).cuda()\n",
    "                    Matrix = torch.Tensor(Matrix).cuda()\n",
    "                    Next_O = torch.Tensor(Next_O).cuda()\n",
    "                    Next_Matrix = torch.Tensor(Next_Matrix).cuda()\n",
    "\n",
    "                    q_values = model(O, Matrix)\n",
    "                    q_values = model(O, Matrix)[:,0, :]\n",
    "                    target_q_values = model_tar(Next_O, Next_Matrix).max(dim = 2)[0][:,0]\n",
    "                    target_q_values = np.array(target_q_values.cpu().data)\n",
    "                    expected_q = np.array(q_values.cpu().data)\n",
    "\n",
    "                    for j in range(self.batch_size):\n",
    "                        expected_q[j][A[j][0]] = R[j][0] + (1-D[j][0])*self.gamma*target_q_values[j]\n",
    "\n",
    "                    loss = (q_values - torch.Tensor(expected_q).cuda()).pow(2).mean()\n",
    "                    episode_loss += loss\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    if e%10 == 0:\n",
    "                        with torch.no_grad():\n",
    "                            for p, p_targ in zip(model.parameters(), model_tar.parameters()):\n",
    "                                p_targ.data.mul_(self.tau)\n",
    "                                p_targ.data.add_((1 - self.tau) * p.data)\n",
    "                \n",
    "                if not self.vizier:\n",
    "                    tb_summary_writer.add_scalar('Loss', episode_loss, global_step_count)\n",
    "                \n",
    "                end_step = global_step_count\n",
    "                steps_taken = end_step - start_step\n",
    "                \n",
    "                print(str(i_episode)+ \" Episode Number Steps Taken: \", steps_taken)\n",
    "                \n",
    "                if not self.vizier:\n",
    "                    tb_summary_writer.add_scalar('Steps Taken Per Episode', steps_taken, i_episode)\n",
    "    \n",
    "            # Print the highest score to the file\n",
    "            self.file.write('Tryout[{}]: (hidden_dim={}, max_step={}, gamma={}, n_episode={}, buffer_size={}, batch_size={}, n_epoch={}, epsilon={}, tau={}, learning_rate={}): \\t ---> \\t Highest Score: {}\\n'.format(\n",
    "                tryout_index, self.hidden_dim, self.max_step, self.gamma, self.n_episode, self.buffer_size, self.batch_size, self.n_epoch, self.epsilon, self.tau, self.learning_rate, self.highest_scores[tryout_index]\n",
    "            ))\n",
    "            \n",
    "            self.file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK NUMBER  0  DEST:  0 0\n",
      "-------\n",
      "TRYOUT[0]: (hidden_dim=64, max_step=5000, gamma=0.99, n_episode=800, buffer_size=1000000, batch_size=64, n_epoch=100, epsilon=0.7, tau=0.95, learning_rate=5e-05)\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  22\n",
      "1 Episode Duration:  0.2985050678253174\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  31\n",
      "2 Episode Duration:  0.30460333824157715\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  44\n",
      "3 Episode Duration:  0.3133096694946289\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  44\n",
      "4 Episode Duration:  0.3130500316619873\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  71\n",
      "5 Episode Duration:  0.3345818519592285\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "6 Episode Duration:  0.2820136547088623\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  4\n",
      "7 Episode Duration:  0.2831916809082031\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  4\n",
      "8 Episode Duration:  0.28455066680908203\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  6\n",
      "9 Episode Duration:  0.2849314212799072\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  42\n",
      "10 Episode Duration:  0.31190967559814453\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "11 Episode Duration:  0.28363585472106934\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  10\n",
      "12 Episode Duration:  0.29068922996520996\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  33\n",
      "13 Episode Duration:  0.3041565418243408\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  27\n",
      "14 Episode Duration:  0.30033397674560547\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  56\n",
      "15 Episode Duration:  0.3242917060852051\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  2\n",
      "16 Episode Duration:  0.28374576568603516\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  38\n",
      "17 Episode Duration:  0.31417322158813477\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  7\n",
      "18 Episode Duration:  0.2920949459075928\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  7\n",
      "19 Episode Duration:  0.2902536392211914\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  6\n",
      "1.0\n",
      "20 Episode Duration:  0.2889070510864258\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  89\n",
      "21 Episode Duration:  0.35297179222106934\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  52\n",
      "22 Episode Duration:  0.32384204864501953\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  71\n",
      "23 Episode Duration:  0.3379549980163574\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  20\n",
      "24 Episode Duration:  0.3000352382659912\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  15\n",
      "25 Episode Duration:  0.29590368270874023\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  6\n",
      "26 Episode Duration:  0.2886030673980713\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  4\n",
      "27 Episode Duration:  0.2875983715057373\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  39\n",
      "28 Episode Duration:  0.3107340335845947\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  3\n",
      "29 Episode Duration:  0.2831394672393799\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  61\n",
      "30 Episode Duration:  0.325420618057251\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  1\n",
      "31 Episode Duration:  0.28160762786865234\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  64\n",
      "32 Episode Duration:  0.3273739814758301\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  13\n",
      "33 Episode Duration:  0.2892038822174072\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  1\n",
      "34 Episode Duration:  0.2839508056640625\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  24\n",
      "35 Episode Duration:  0.29767274856567383\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  2\n",
      "36 Episode Duration:  0.2813606262207031\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  2\n",
      "37 Episode Duration:  0.282062292098999\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  40\n",
      "38 Episode Duration:  0.3103783130645752\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  14\n",
      "39 Episode Duration:  0.29099178314208984\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "1.0\n",
      "40 Episode Duration:  0.2828795909881592\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  14\n",
      "41 Episode Duration:  0.29195094108581543\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  5\n",
      "42 Episode Duration:  0.2834188938140869\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  24\n",
      "43 Episode Duration:  0.29669618606567383\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  29\n",
      "44 Episode Duration:  0.30230116844177246\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  5\n",
      "45 Episode Duration:  0.28399014472961426\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  7\n",
      "46 Episode Duration:  0.2842681407928467\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  4\n",
      "47 Episode Duration:  0.28252744674682617\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  1\n",
      "48 Episode Duration:  0.28157472610473633\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  35\n",
      "49 Episode Duration:  0.3049650192260742\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  36\n",
      "50 Episode Duration:  0.30654191970825195\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  19\n",
      "51 Episode Duration:  0.2951395511627197\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  5\n",
      "52 Episode Duration:  0.2834908962249756\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  19\n",
      "53 Episode Duration:  0.2935526371002197\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  135\n",
      "54 Episode Duration:  0.38024258613586426\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  9\n",
      "55 Episode Duration:  0.2863924503326416\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  6\n",
      "56 Episode Duration:  0.28646421432495117\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  2\n",
      "57 Episode Duration:  0.28193187713623047\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  9\n",
      "58 Episode Duration:  0.2862727642059326\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  81\n",
      "59 Episode Duration:  0.3388185501098633\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  95\n",
      "1.0\n",
      "60 Episode Duration:  0.3508274555206299\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  41\n",
      "61 Episode Duration:  0.30988001823425293\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  33\n",
      "62 Episode Duration:  0.3040885925292969\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  71\n",
      "63 Episode Duration:  0.3326852321624756\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  5\n",
      "64 Episode Duration:  0.28362321853637695\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  30\n",
      "65 Episode Duration:  0.3034780025482178\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  28\n",
      "66 Episode Duration:  0.30157971382141113\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  13\n",
      "67 Episode Duration:  0.29064440727233887\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  1\n",
      "68 Episode Duration:  0.28145861625671387\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  4\n",
      "69 Episode Duration:  0.2830162048339844\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  75\n",
      "70 Episode Duration:  0.33704400062561035\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  12\n",
      "71 Episode Duration:  0.28896522521972656\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  24\n",
      "72 Episode Duration:  0.29788851737976074\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  48\n",
      "73 Episode Duration:  0.31641340255737305\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  15\n",
      "74 Episode Duration:  0.2917647361755371\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  46\n",
      "75 Episode Duration:  0.3143348693847656\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  24\n",
      "76 Episode Duration:  0.29911303520202637\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  7\n",
      "77 Episode Duration:  0.28595590591430664\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  13\n",
      "78 Episode Duration:  0.28982043266296387\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  38\n",
      "79 Episode Duration:  0.3115873336791992\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  33\n",
      "1.0\n",
      "80 Episode Duration:  0.30605554580688477\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  24\n",
      "81 Episode Duration:  0.2976722717285156\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Episode Duration:  0.30750179290771484\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  114\n",
      "83 Episode Duration:  0.36647486686706543\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  25\n",
      "84 Episode Duration:  0.2985823154449463\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  19\n",
      "85 Episode Duration:  0.2946202754974365\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  7\n",
      "86 Episode Duration:  0.2865917682647705\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  1\n",
      "87 Episode Duration:  0.28113698959350586\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  13\n",
      "88 Episode Duration:  0.29022789001464844\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  58\n",
      "89 Episode Duration:  0.32399892807006836\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  123\n",
      "90 Episode Duration:  0.37139225006103516\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  2\n",
      "91 Episode Duration:  0.28209495544433594\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  22\n",
      "92 Episode Duration:  0.2975146770477295\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  9\n",
      "93 Episode Duration:  0.2868504524230957\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  2\n",
      "94 Episode Duration:  0.2814478874206543\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  2\n",
      "95 Episode Duration:  0.28241443634033203\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  16\n",
      "96 Episode Duration:  0.2931337356567383\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  10\n",
      "97 Episode Duration:  0.2875995635986328\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  28\n",
      "98 Episode Duration:  0.30106639862060547\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  9\n",
      "99 Episode Duration:  0.28815269470214844\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  72\n",
      "1.0\n",
      "100 Episode Duration:  0.33364129066467285\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  49\n",
      "101 Episode Duration:  0.31880831718444824\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  7\n",
      "102 Episode Duration:  0.2864420413970947\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  7\n",
      "103 Episode Duration:  0.28562378883361816\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  1\n",
      "104 Episode Duration:  0.28125858306884766\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  23\n",
      "105 Episode Duration:  0.2974510192871094\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  7\n",
      "106 Episode Duration:  0.2862403392791748\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  1\n",
      "107 Episode Duration:  0.2810547351837158\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  1\n",
      "108 Episode Duration:  0.28145456314086914\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  2\n",
      "109 Episode Duration:  0.28281402587890625\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  19\n",
      "110 Episode Duration:  0.2947273254394531\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  7\n",
      "111 Episode Duration:  0.28619861602783203\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  17\n",
      "112 Episode Duration:  0.2935914993286133\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  21\n",
      "113 Episode Duration:  0.29711198806762695\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  5\n",
      "114 Episode Duration:  0.284024715423584\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  3\n",
      "115 Episode Duration:  0.2851743698120117\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  17\n",
      "116 Episode Duration:  0.29497838020324707\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  3\n",
      "117 Episode Duration:  0.28369855880737305\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  6\n",
      "118 Episode Duration:  0.28582167625427246\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  1\n",
      "119 Episode Duration:  0.2829172611236572\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  36\n",
      "1.0\n",
      "120 Episode Duration:  0.31049394607543945\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  15\n",
      "121 Episode Duration:  0.2966880798339844\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  13\n",
      "122 Episode Duration:  0.2952702045440674\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  2\n",
      "123 Episode Duration:  0.2866995334625244\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  75\n",
      "124 Episode Duration:  0.34586548805236816\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  2\n",
      "125 Episode Duration:  0.28673815727233887\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "126 Episode Duration:  0.2843465805053711\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  9\n",
      "127 Episode Duration:  0.28750133514404297\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  7\n",
      "128 Episode Duration:  0.2855215072631836\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  46\n",
      "129 Episode Duration:  0.31530141830444336\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  1\n",
      "130 Episode Duration:  0.28086304664611816\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  67\n",
      "131 Episode Duration:  0.32835960388183594\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  110\n",
      "132 Episode Duration:  0.36200785636901855\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  10\n",
      "133 Episode Duration:  0.2888343334197998\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  12\n",
      "134 Episode Duration:  0.2939925193786621\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  71\n",
      "135 Episode Duration:  0.334073543548584\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  16\n",
      "136 Episode Duration:  0.29226112365722656\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  4\n",
      "137 Episode Duration:  0.2827932834625244\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  121\n",
      "138 Episode Duration:  0.37126994132995605\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  35\n",
      "139 Episode Duration:  0.30644893646240234\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  19\n",
      "1.0\n",
      "140 Episode Duration:  0.29453325271606445\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  29\n",
      "141 Episode Duration:  0.30269527435302734\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  3\n",
      "142 Episode Duration:  0.28308773040771484\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  1\n",
      "143 Episode Duration:  0.28157997131347656\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  30\n",
      "144 Episode Duration:  0.3024442195892334\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  7\n",
      "145 Episode Duration:  0.28699445724487305\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  23\n",
      "146 Episode Duration:  0.299990177154541\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  6\n",
      "147 Episode Duration:  0.28493499755859375\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  44\n",
      "148 Episode Duration:  0.31523966789245605\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  21\n",
      "149 Episode Duration:  0.29555535316467285\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  6\n",
      "150 Episode Duration:  0.2846817970275879\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  3\n",
      "151 Episode Duration:  0.28292250633239746\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  2\n",
      "152 Episode Duration:  0.2826414108276367\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  2\n",
      "153 Episode Duration:  0.2820119857788086\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  73\n",
      "154 Episode Duration:  0.3346383571624756\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  3\n",
      "155 Episode Duration:  0.28334546089172363\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  29\n",
      "156 Episode Duration:  0.3020470142364502\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  13\n",
      "157 Episode Duration:  0.2903776168823242\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  121\n",
      "158 Episode Duration:  0.3707878589630127\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  18\n",
      "159 Episode Duration:  0.29435062408447266\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  2\n",
      "1.0\n",
      "160 Episode Duration:  0.28225231170654297\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "161 Episode Duration:  0.28211069107055664\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  9\n",
      "162 Episode Duration:  0.28667593002319336\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  146\n",
      "163 Episode Duration:  0.3876228332519531\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 Episode Duration:  0.29467225074768066\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  4\n",
      "165 Episode Duration:  0.2921581268310547\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  8\n",
      "166 Episode Duration:  0.29005885124206543\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  63\n",
      "167 Episode Duration:  0.3283848762512207\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  3\n",
      "168 Episode Duration:  0.2843019962310791\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  1\n",
      "169 Episode Duration:  0.2805812358856201\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  42\n",
      "170 Episode Duration:  0.31197381019592285\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  33\n",
      "171 Episode Duration:  0.306119441986084\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  9\n",
      "172 Episode Duration:  0.2873513698577881\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  2\n",
      "173 Episode Duration:  0.28186774253845215\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  1\n",
      "174 Episode Duration:  0.28218984603881836\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  10\n",
      "175 Episode Duration:  0.288463830947876\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  21\n",
      "176 Episode Duration:  0.2958815097808838\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  24\n",
      "177 Episode Duration:  0.29815077781677246\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  2\n",
      "178 Episode Duration:  0.2822892665863037\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  75\n",
      "179 Episode Duration:  0.3358731269836426\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  424\n",
      "1.0\n",
      "180 Episode Duration:  0.6017587184906006\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  14\n",
      "181 Episode Duration:  0.29569149017333984\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  1\n",
      "182 Episode Duration:  0.2863640785217285\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  8\n",
      "183 Episode Duration:  0.2922670841217041\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  11\n",
      "184 Episode Duration:  0.293651819229126\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  12\n",
      "185 Episode Duration:  0.2939314842224121\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  1\n",
      "186 Episode Duration:  0.2860736846923828\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  9\n",
      "187 Episode Duration:  0.29242849349975586\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  36\n",
      "188 Episode Duration:  0.3116464614868164\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  107\n",
      "189 Episode Duration:  0.36696290969848633\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  53\n",
      "190 Episode Duration:  0.3248429298400879\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  15\n",
      "191 Episode Duration:  0.29613637924194336\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  44\n",
      "192 Episode Duration:  0.31759047508239746\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  26\n",
      "193 Episode Duration:  0.305600643157959\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  3\n",
      "194 Episode Duration:  0.2868380546569824\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  8\n",
      "195 Episode Duration:  0.2911365032196045\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  45\n",
      "196 Episode Duration:  0.3191688060760498\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  23\n",
      "197 Episode Duration:  0.3022794723510742\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  57\n",
      "198 Episode Duration:  0.3272364139556885\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  16\n",
      "199 Episode Duration:  0.297637939453125\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  20\n",
      "1.0\n",
      "200 Episode Duration:  0.30025792121887207\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  1\n",
      "201 Episode Duration:  0.28525733947753906\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  3\n",
      "202 Episode Duration:  0.2880120277404785\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  34\n",
      "203 Episode Duration:  0.31009435653686523\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  126\n",
      "204 Episode Duration:  0.37856340408325195\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  12\n",
      "205 Episode Duration:  0.2942667007446289\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  6\n",
      "206 Episode Duration:  0.2857968807220459\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  25\n",
      "207 Episode Duration:  0.29830384254455566\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  1\n",
      "208 Episode Duration:  0.2815976142883301\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  23\n",
      "209 Episode Duration:  0.29790711402893066\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  24\n",
      "210 Episode Duration:  0.29792046546936035\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  8\n",
      "211 Episode Duration:  0.2883598804473877\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  9\n",
      "212 Episode Duration:  0.2883317470550537\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  59\n",
      "213 Episode Duration:  0.327150821685791\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  13\n",
      "214 Episode Duration:  0.29570889472961426\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  27\n",
      "215 Episode Duration:  0.3069345951080322\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  32\n",
      "216 Episode Duration:  0.3091247081756592\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  57\n",
      "217 Episode Duration:  0.32750415802001953\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  4\n",
      "218 Episode Duration:  0.2879147529602051\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  7\n",
      "219 Episode Duration:  0.2901322841644287\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  16\n",
      "1.0\n",
      "220 Episode Duration:  0.2961297035217285\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  65\n",
      "221 Episode Duration:  0.3340613842010498\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  15\n",
      "222 Episode Duration:  0.2965846061706543\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  71\n",
      "223 Episode Duration:  0.3379063606262207\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  18\n",
      "224 Episode Duration:  0.29763054847717285\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  7\n",
      "225 Episode Duration:  0.2902038097381592\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  23\n",
      "226 Episode Duration:  0.30178380012512207\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  4\n",
      "227 Episode Duration:  0.286513090133667\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  17\n",
      "228 Episode Duration:  0.29433155059814453\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  10\n",
      "229 Episode Duration:  0.2879066467285156\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  5\n",
      "230 Episode Duration:  0.28461217880249023\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  9\n",
      "231 Episode Duration:  0.28816962242126465\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  41\n",
      "232 Episode Duration:  0.3117492198944092\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  3\n",
      "233 Episode Duration:  0.28249216079711914\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  22\n",
      "234 Episode Duration:  0.2985718250274658\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  214\n",
      "235 Episode Duration:  0.43900036811828613\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  2\n",
      "236 Episode Duration:  0.28095054626464844\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  50\n",
      "237 Episode Duration:  0.31713271141052246\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  50\n",
      "238 Episode Duration:  0.31746792793273926\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  11\n",
      "239 Episode Duration:  0.2879631519317627\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  61\n",
      "1.0\n",
      "240 Episode Duration:  0.3262453079223633\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  117\n",
      "241 Episode Duration:  0.3671298027038574\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  48\n",
      "242 Episode Duration:  0.3160054683685303\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  80\n",
      "243 Episode Duration:  0.3399021625518799\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  69\n",
      "244 Episode Duration:  0.3315000534057617\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  66\n",
      "245 Episode Duration:  0.32898640632629395\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246 Episode Duration:  0.3033449649810791\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  12\n",
      "247 Episode Duration:  0.2895331382751465\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  102\n",
      "248 Episode Duration:  0.3552858829498291\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  54\n",
      "249 Episode Duration:  0.32021307945251465\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  41\n",
      "250 Episode Duration:  0.31090831756591797\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  8\n",
      "251 Episode Duration:  0.285794734954834\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  2\n",
      "252 Episode Duration:  0.28147196769714355\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  137\n",
      "253 Episode Duration:  0.38245105743408203\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  41\n",
      "254 Episode Duration:  0.31274890899658203\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  2\n",
      "255 Episode Duration:  0.2813444137573242\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  7\n",
      "256 Episode Duration:  0.2858152389526367\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  15\n",
      "257 Episode Duration:  0.29027843475341797\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  2\n",
      "258 Episode Duration:  0.2808959484100342\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "259 Episode Duration:  0.2822835445404053\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  209\n",
      "1.0\n",
      "260 Episode Duration:  0.43569421768188477\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  56\n",
      "261 Episode Duration:  0.32192420959472656\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  11\n",
      "262 Episode Duration:  0.2952580451965332\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  2\n",
      "263 Episode Duration:  0.28530240058898926\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  43\n",
      "264 Episode Duration:  0.31200575828552246\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  21\n",
      "265 Episode Duration:  0.2968435287475586\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  3\n",
      "266 Episode Duration:  0.2828857898712158\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "267 Episode Duration:  0.2819204330444336\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  22\n",
      "268 Episode Duration:  0.2977166175842285\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  34\n",
      "269 Episode Duration:  0.3058278560638428\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  13\n",
      "270 Episode Duration:  0.2903132438659668\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  14\n",
      "271 Episode Duration:  0.2906503677368164\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  107\n",
      "272 Episode Duration:  0.3611948490142822\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  6\n",
      "273 Episode Duration:  0.2862272262573242\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  82\n",
      "274 Episode Duration:  0.34029293060302734\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  4\n",
      "275 Episode Duration:  0.2843503952026367\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  46\n",
      "276 Episode Duration:  0.31452512741088867\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  2\n",
      "277 Episode Duration:  0.28139472007751465\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  35\n",
      "278 Episode Duration:  0.3071596622467041\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  367\n",
      "279 Episode Duration:  0.5522232055664062\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  10\n",
      "1.0\n",
      "280 Episode Duration:  0.288623571395874\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  40\n",
      "281 Episode Duration:  0.3105926513671875\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  114\n",
      "282 Episode Duration:  0.36500096321105957\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  47\n",
      "283 Episode Duration:  0.3148064613342285\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  9\n",
      "284 Episode Duration:  0.2871072292327881\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  15\n",
      "285 Episode Duration:  0.290729284286499\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  39\n",
      "286 Episode Duration:  0.3090484142303467\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  74\n",
      "287 Episode Duration:  0.3355526924133301\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  42\n",
      "288 Episode Duration:  0.31170010566711426\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  18\n",
      "289 Episode Duration:  0.2945282459259033\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  6\n",
      "290 Episode Duration:  0.2893376350402832\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  1\n",
      "291 Episode Duration:  0.28562331199645996\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  20\n",
      "292 Episode Duration:  0.2995004653930664\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  14\n",
      "293 Episode Duration:  0.2950015068054199\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  6\n",
      "294 Episode Duration:  0.28955817222595215\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  1\n",
      "295 Episode Duration:  0.2811708450317383\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  53\n",
      "296 Episode Duration:  0.31935572624206543\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  7\n",
      "297 Episode Duration:  0.28975510597229004\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  7\n",
      "298 Episode Duration:  0.2860727310180664\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  12\n",
      "299 Episode Duration:  0.28881335258483887\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  1\n",
      "1.0\n",
      "300 Episode Duration:  0.28233933448791504\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  10\n",
      "301 Episode Duration:  0.288496732711792\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  1\n",
      "302 Episode Duration:  0.2809782028198242\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  37\n",
      "303 Episode Duration:  0.3082120418548584\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  5\n",
      "304 Episode Duration:  0.2849278450012207\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  1\n",
      "305 Episode Duration:  0.280719518661499\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  74\n",
      "306 Episode Duration:  0.3354034423828125\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  20\n",
      "307 Episode Duration:  0.2967994213104248\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  2\n",
      "308 Episode Duration:  0.28217363357543945\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  44\n",
      "309 Episode Duration:  0.31296634674072266\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  65\n",
      "310 Episode Duration:  0.3303871154785156\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  27\n",
      "311 Episode Duration:  0.301969051361084\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  4\n",
      "312 Episode Duration:  0.285689115524292\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  246\n",
      "313 Episode Duration:  0.4707047939300537\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  261\n",
      "314 Episode Duration:  0.4749412536621094\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  3\n",
      "315 Episode Duration:  0.2832036018371582\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  8\n",
      "316 Episode Duration:  0.28772425651550293\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "317 Episode Duration:  0.28174924850463867\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  44\n",
      "318 Episode Duration:  0.31615257263183594\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  199\n",
      "319 Episode Duration:  0.4300858974456787\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  60\n",
      "1.0\n",
      "320 Episode Duration:  0.32547998428344727\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  2\n",
      "321 Episode Duration:  0.2823188304901123\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  124\n",
      "322 Episode Duration:  0.373854398727417\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  13\n",
      "323 Episode Duration:  0.2902507781982422\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  1\n",
      "324 Episode Duration:  0.28154540061950684\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  27\n",
      "325 Episode Duration:  0.3027191162109375\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  25\n",
      "326 Episode Duration:  0.2992973327636719\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  521\n",
      "327 Episode Duration:  0.6696569919586182\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 Episode Duration:  0.2820556163787842\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  21\n",
      "329 Episode Duration:  0.2955155372619629\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  3\n",
      "330 Episode Duration:  0.28327250480651855\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  208\n",
      "331 Episode Duration:  0.4359130859375\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  64\n",
      "332 Episode Duration:  0.3282961845397949\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  17\n",
      "333 Episode Duration:  0.29418444633483887\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  21\n",
      "334 Episode Duration:  0.29571533203125\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  3\n",
      "335 Episode Duration:  0.2816941738128662\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  2\n",
      "336 Episode Duration:  0.2822580337524414\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  474\n",
      "337 Episode Duration:  0.6383216381072998\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "338 Episode Duration:  0.28228163719177246\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  1\n",
      "339 Episode Duration:  0.2811107635498047\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  1\n",
      "1.0\n",
      "340 Episode Duration:  0.2810482978820801\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  20\n",
      "341 Episode Duration:  0.2947862148284912\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  35\n",
      "342 Episode Duration:  0.30797791481018066\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  36\n",
      "343 Episode Duration:  0.30710506439208984\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  20\n",
      "344 Episode Duration:  0.2950618267059326\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  27\n",
      "345 Episode Duration:  0.30112409591674805\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  3\n",
      "346 Episode Duration:  0.2826871871948242\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  5\n",
      "347 Episode Duration:  0.28383326530456543\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  14\n",
      "348 Episode Duration:  0.29107165336608887\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  4\n",
      "349 Episode Duration:  0.28392839431762695\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  120\n",
      "350 Episode Duration:  0.36980700492858887\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  102\n",
      "351 Episode Duration:  0.3562772274017334\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  57\n",
      "352 Episode Duration:  0.3231954574584961\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  2\n",
      "353 Episode Duration:  0.2818455696105957\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  2\n",
      "354 Episode Duration:  0.2817649841308594\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  73\n",
      "355 Episode Duration:  0.3357877731323242\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  13\n",
      "356 Episode Duration:  0.29328012466430664\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  1\n",
      "357 Episode Duration:  0.28629422187805176\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  2\n",
      "358 Episode Duration:  0.28786468505859375\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  6\n",
      "359 Episode Duration:  0.29230260848999023\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  2\n",
      "1.0\n",
      "360 Episode Duration:  0.28607892990112305\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  48\n",
      "361 Episode Duration:  0.32193565368652344\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  11\n",
      "362 Episode Duration:  0.2934718132019043\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  2\n",
      "363 Episode Duration:  0.2861292362213135\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  19\n",
      "364 Episode Duration:  0.30060720443725586\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  186\n",
      "365 Episode Duration:  0.42397618293762207\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  31\n",
      "366 Episode Duration:  0.3075902462005615\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  2\n",
      "367 Episode Duration:  0.28757143020629883\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  197\n",
      "368 Episode Duration:  0.43155765533447266\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  28\n",
      "369 Episode Duration:  0.30519700050354004\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  13\n",
      "370 Episode Duration:  0.29648447036743164\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  1\n",
      "371 Episode Duration:  0.28628110885620117\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  249\n",
      "372 Episode Duration:  0.4703059196472168\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  57\n",
      "373 Episode Duration:  0.3289146423339844\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  61\n",
      "374 Episode Duration:  0.33018016815185547\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  4\n",
      "375 Episode Duration:  0.2879750728607178\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  118\n",
      "376 Episode Duration:  0.3744025230407715\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  2\n",
      "377 Episode Duration:  0.2864551544189453\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  91\n",
      "378 Episode Duration:  0.3528592586517334\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  19\n",
      "379 Episode Duration:  0.30356740951538086\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  135\n",
      "1.0\n",
      "380 Episode Duration:  0.3860483169555664\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  18\n",
      "381 Episode Duration:  0.2989377975463867\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  2\n",
      "382 Episode Duration:  0.2881622314453125\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  24\n",
      "383 Episode Duration:  0.30306005477905273\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  55\n",
      "384 Episode Duration:  0.3253045082092285\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  2\n",
      "385 Episode Duration:  0.2873075008392334\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  27\n",
      "386 Episode Duration:  0.30237674713134766\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  39\n",
      "387 Episode Duration:  0.30991387367248535\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  25\n",
      "388 Episode Duration:  0.3002126216888428\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  79\n",
      "389 Episode Duration:  0.340421199798584\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  108\n",
      "390 Episode Duration:  0.361480712890625\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  4\n",
      "391 Episode Duration:  0.28470468521118164\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  2\n",
      "392 Episode Duration:  0.2830085754394531\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  17\n",
      "393 Episode Duration:  0.293168306350708\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  3\n",
      "394 Episode Duration:  0.2832069396972656\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  20\n",
      "395 Episode Duration:  0.2969849109649658\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  25\n",
      "396 Episode Duration:  0.2994043827056885\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  5\n",
      "397 Episode Duration:  0.28426384925842285\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  29\n",
      "398 Episode Duration:  0.30533623695373535\n",
      "TASK NUMBER  0  DEST:  1 2\n",
      "Task  0  completed at step  32\n",
      "399 Episode Duration:  0.30553722381591797\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  3\n",
      "1.0\n",
      "400 Episode Duration:  0.28424739837646484\n",
      "TASK NUMBER  0  DEST:  2 2\n",
      "Task  0  completed at step  170\n",
      "401 Episode Duration:  0.4135403633117676\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  139\n",
      "402 Episode Duration:  0.386150598526001\n",
      "TASK NUMBER  0  DEST:  2 0\n",
      "Task  0  completed at step  112\n",
      "403 Episode Duration:  0.3659944534301758\n",
      "TASK NUMBER  0  DEST:  0 1\n",
      "Task  0  completed at step  13\n",
      "404 Episode Duration:  0.2908642292022705\n",
      "TASK NUMBER  0  DEST:  1 1\n",
      "Task  0  completed at step  27\n",
      "405 Episode Duration:  0.30081844329833984\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  142\n",
      "406 Episode Duration:  0.38759374618530273\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  8\n",
      "407 Episode Duration:  0.28760504722595215\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  2\n",
      "408 Episode Duration:  0.281904935836792\n",
      "TASK NUMBER  0  DEST:  0 2\n",
      "Task  0  completed at step  3\n",
      "409 Episode Duration:  0.28246426582336426\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410 Episode Duration:  0.4158294200897217\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  60\n",
      "411 Episode Duration:  0.32550811767578125\n",
      "TASK NUMBER  0  DEST:  2 1\n",
      "Task  0  completed at step  9\n",
      "412 Episode Duration:  0.286862850189209\n",
      "TASK NUMBER  0  DEST:  0 0\n",
      "Task  0  completed at step  13\n",
      "413 Episode Duration:  0.29100823402404785\n",
      "TASK NUMBER  0  DEST:  1 0\n",
      "Task  0  completed at step  101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-661dc693ffa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRID_DIM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"DIM_\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_TASKS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"TASKS_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_ATTENTION_HEADS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ATT_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWAIT_TILL_ALL_TASKS_DONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"WAITALLTASKS_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUSE_OBS_DIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"USEOBSDIST_SOFTREWARD.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-ca81d2f438ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                     \u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNext_O\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNext_Matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                     \u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0mMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-695263b32dbe>\u001b[0m in \u001b[0;36mgetBatch\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \"\"\"\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2997\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m     \"\"\"\n\u001b[0;32m-> 2999\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3000\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_file_name = str(GRID_DIM) + \"DIM_\"+ str(NUM_TASKS) +\"TASKS_\" + str(NUM_ATTENTION_HEADS) + \"ATT_\" + str(int(WAIT_TILL_ALL_TASKS_DONE)) + \"WAITALLTASKS_\" + str(int(USE_OBS_DIST)) + \"USEOBSDIST_SOFTREWARD.txt\"\n",
    "training = Training(log_file_name, False)\n",
    "training.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D64gsJRimGp"
   },
   "source": [
    "https://github.com/jiechuanjiang/pytorch_DGN/blob/main/Surviving/DGN%2BATOC/main.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DRL-FinalProject-GridWorld.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
